{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer    \n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Incializando as stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivessem\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\", \"-\", \"_\", \"\\“\", \"\\\"\", \"|\", \"/\", \":\", \",\", \".\", \"?\", \"!\", \"*\", \"(\", \")\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lendo os arquivos e retirando as stopwords com pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloroquina = pd.read_excel(\"ep2-cloroquina-treino.xlsx\",sheet_name='train',usecols=['texto','posicao'])\n",
    "x = df_cloroquina.texto.apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stopwords))\n",
    "y = df_cloroquina.posicao\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando os dados textuais em sequências númericas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=11000)\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "x_train_numerico = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_numerico = tokenizer.texts_to_sequences(x_test)\n",
    "tamanho_vocabulario = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando os dados de treino e teste em entradas para a rede neural através de padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_embedding = 300\n",
    "\n",
    "x_train_padded = pad_sequences(x_train_numerico, padding='post', maxlen=tamanho_embedding)\n",
    "x_test_padded = pad_sequences(x_test_numerico, padding='post', maxlen=tamanho_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a lista de palavras (token) de cada linha de dado do arquivo de dados, o TfidfVectorizer está sendo usado como filtro de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=[1,1], analyzer='word', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "\n",
    "analyzer = tfidf.build_analyzer()\n",
    "lista_tokens = []\n",
    "\n",
    "for item in x:\n",
    "    tokens = analyzer(item)\n",
    "    lista_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando embeddings com vetores de tamanho 300 com a lista de tokens criada anteriormente. Logo após, utilizando a matriz de pesos do modelo Word2Vec para criar uma camada de embeddings para a rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(lista_tokens, vector_size=tamanho_embedding, workers=8, min_count=1)\n",
    "num_palavras = word2vec.wv.vectors.shape[0]\n",
    "embedding_layer = Embedding(num_palavras, tamanho_embedding, weights=[word2vec.wv.vectors], input_length=tamanho_embedding, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constroi uma rede neural CNN utilizando a biblioteca Keras, incorpora o embedding criado com Word2Vec na rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constroi_modelo_cnn():\n",
    "    modelo = Sequential()\n",
    "    \n",
    "    modelo.add(embedding_layer)\n",
    "    modelo.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    modelo.add(MaxPooling1D(pool_size=2))\n",
    "    #Dropouts reduzem o overfitting da rede ao desativar neurônios durante o treinamento.\n",
    "    modelo.add(Dropout(0.2))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria uma função de parada antecipada para evitar aumento da função loss da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma o modelo neural do Keras em um modelo que pode ser entendido pelo Sklearn (wrapper) e inicializa o treinamento e validações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 93ms/step - loss: 0.7115 - accuracy: 0.5164\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.6459 - accuracy: 0.6453\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 89ms/step - loss: 0.3293 - accuracy: 0.8719\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.1370 - accuracy: 0.9527\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 92ms/step - loss: 0.0558 - accuracy: 0.9854\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 91ms/step - loss: 0.0302 - accuracy: 0.9931\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.0160 - accuracy: 0.9964\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 92ms/step - loss: 0.0086 - accuracy: 0.9980\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 91ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 93ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 91ms/step - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 12s 94ms/step - loss: 0.4245 - accuracy: 0.8020\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.0754 - accuracy: 0.9808\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 92ms/step - loss: 0.0280 - accuracy: 0.9931\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 92ms/step - loss: 0.0138 - accuracy: 0.9977\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0078 - accuracy: 0.9982\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 91ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 7.1924e-04 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0153 - accuracy: 0.9946\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 89ms/step - loss: 0.2849 - accuracy: 0.8852\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0210 - accuracy: 0.9962\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 91ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 12s 96ms/step - loss: 8.1859e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 12s 99ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 12s 97ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 93ms/step - loss: 0.2616 - accuracy: 0.8895\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 13s 102ms/step - loss: 0.0116 - accuracy: 0.9987\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 12s 99ms/step - loss: 0.0030 - accuracy: 0.9997\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 12s 94ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 12s 99ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 12s 101ms/step - loss: 6.5841e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 12s 95ms/step - loss: 3.7400e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 89ms/step - loss: 2.8078e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 2.3792e-04 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 3.5884e-04 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 2.4731e-04 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.2286 - accuracy: 0.9105\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0090 - accuracy: 0.9982\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 4.8094e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 3.9902e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 2.5158e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 89ms/step - loss: 1.4901e-04 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.3764e-04 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 8.0240e-05 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 0.1798 - accuracy: 0.9299\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 8.9593e-04 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 8.9955e-04 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 4.8822e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 91ms/step - loss: 3.9076e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.5570e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 9.2480e-05 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 6.8307e-05 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 8.6750e-05 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.1498 - accuracy: 0.9432\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.0038 - accuracy: 0.9997\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 5.3373e-04 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 3.1307e-04 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 2.1565e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.8605e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.2167e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 8.6380e-05 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 9.0141e-05 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 5.1514e-05 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.1884 - accuracy: 0.9225\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 90ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 7.7742e-04 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 4.8368e-04 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 2.2960e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.5182e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.1920e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.4796e-04 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 8.9421e-05 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 4.9708e-05 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.2068 - accuracy: 0.9169\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 9.9071e-04 - accuracy: 1.0000\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 6.2394e-04 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 3.4101e-04 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 3.0890e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.6953e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 89ms/step - loss: 1.2595e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 8.7425e-05 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.0399e-04 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 6.6077e-05 - accuracy: 1.0000\n",
      "Epoch 1/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 0.1704 - accuracy: 0.9351\n",
      "Epoch 2/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 0.0031 - accuracy: 0.9997\n",
      "Epoch 3/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 4/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 6.4787e-04 - accuracy: 1.0000\n",
      "Epoch 5/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 6.0886e-04 - accuracy: 1.0000\n",
      "Epoch 6/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 3.8283e-04 - accuracy: 1.0000\n",
      "Epoch 7/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.9427e-04 - accuracy: 1.0000\n",
      "Epoch 8/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 1.3801e-04 - accuracy: 1.0000\n",
      "Epoch 9/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.3363e-04 - accuracy: 1.0000\n",
      "Epoch 10/11\n",
      "123/123 [==============================] - 11s 88ms/step - loss: 1.6203e-04 - accuracy: 1.0000\n",
      "Epoch 11/11\n",
      "123/123 [==============================] - 11s 87ms/step - loss: 7.5801e-05 - accuracy: 1.0000\n",
      "0.9809195402298851\n"
     ]
    }
   ],
   "source": [
    "rede_neural = KerasClassifier(build_fn=constroi_modelo_cnn, epochs=11)\n",
    "kfolds = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "resultado = cross_val_score(rede_neural, x_train_padded, y_train, cv=kfolds, scoring='accuracy', fit_params={'callbacks': [early_stopping]}).mean()\n",
    "print(\"Acuracia de treino: \" + resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testa a acuracia da rede com os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.6967 - accuracy: 0.6394\n",
      "Epoch 2/11\n",
      "34/34 [==============================] - 3s 85ms/step - loss: 0.3883 - accuracy: 0.8261\n",
      "Epoch 3/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.3659 - accuracy: 0.8399\n",
      "Epoch 4/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.2683 - accuracy: 0.8822\n",
      "Epoch 5/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.1921 - accuracy: 0.9218\n",
      "Epoch 6/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.1484 - accuracy: 0.9485\n",
      "Epoch 7/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.1114 - accuracy: 0.9641\n",
      "Epoch 8/11\n",
      "34/34 [==============================] - 3s 85ms/step - loss: 0.0765 - accuracy: 0.9779\n",
      "Epoch 9/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.0595 - accuracy: 0.9862\n",
      "Epoch 10/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.0432 - accuracy: 0.9890\n",
      "Epoch 11/11\n",
      "34/34 [==============================] - 3s 86ms/step - loss: 0.0307 - accuracy: 0.9926\n",
      "0.9954001839926403\n"
     ]
    }
   ],
   "source": [
    "rede_neural.fit(x_test_padded, y_test)\n",
    "predicao = rede_neural.predict(x_test_padded)\n",
    "acuracia = accuracy_score(predicao, y_test)\n",
    "print(\"Acuracia de teste: \" + acuracia)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fc3c70bdf126d36ef05241663b6e1e6a74791aef0a540d9607b18a3d8930c22"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
